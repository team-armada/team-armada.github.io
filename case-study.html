<!DOCTYPE html>
<html data-wf-page="5f71dd169010d6326b65485d">
  <head>
    <meta charset="utf-8" />
    <title>Armada • Case Study</title>
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="assets/css/style.css" rel="stylesheet" type="text/css" />
    <script
      src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"
      type="text/javascript"
    ></script>
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Inter:regular,500,600,700"
      media="all"
    />
    <script type="text/javascript">
      WebFont.load({ google: { families: ['Inter:regular,500,600,700'] } });
    </script>
    <script type="text/javascript">
      !(function (o, c) {
        var n = c.documentElement,
          t = ' w-mod-';
        (n.className += t + 'js'),
          ('ontouchstart' in o ||
            (o.DocumentTouch && c instanceof DocumentTouch)) &&
            (n.className += t + 'touch');
      })(window, document);
    </script>
    <link href="assets/logo.png" rel="shortcut icon" type="image/x-icon" />
    <link href="assets/logo.png" rel="apple-touch-icon" />
    <script
      src="https://kit.fontawesome.com/d019875f94.js"
      crossorigin="anonymous"
    ></script>
    <meta
      name="image"
      property="og:image"
      content="assets/images/thumbnail.png"
    />
  </head>

  <body>
    <div class="navigation-wrap">
      <div
        data-collapse="medium"
        data-animation="default"
        data-duration="400"
        role="banner"
        class="navigation w-nav"
      >
        <div class="navigation-container">
          <div class="navigation-left">
            <a
              href="index.html"
              aria-current="page"
              class="brand w-nav-brand w—current"
              aria-label="home"
            >
              <img src="assets/logo.png" alt="" class="template-logo" />
            </a>
            <nav role="navigation" class="nav-menu w-nav-menu">
              <a href="case-study.html" class="link-block w-inline-block">
                <div style="color: var(--primary)">Case Study</div>
              </a>
              <a href="presentation.html" class="link-block w-inline-block">
                <div>Presentation</div>
              </a>
              <a href="team.html" class="link-block w-inline-block">
                <div>The Team</div>
              </a>
            </nav>
          </div>
          <div class="navigation-right">
            <div class="login-buttons">
              <a href="https://github.com/team-armada" target="_blank">
                <span style="color: var(--white)">
                  <i class="fab fa-github fa-lg"></i>
                </span>
              </a>
            </div>
          </div>
        </div>
        <div class="w-nav-overlay" data-wf-ignore="" id="w-nav-overlay-0"></div>
      </div>
    </div>
    <div id="sidebar" class="toc"></div>

    <div class="section header">
      <article class="container case-study-container">
        <div class="hero-text-container">
          <h1 class="h1 centered gradient-text">Case Study</h1>
        </div>

        <div id="case-study">
          <br />
          <br />
          <!-- Section 1 -->
          <h2 class="h2">1. Introduction</h2>
          <br />
          <h3>1.1. What is Armada?</h3>
          <p>
            Armada is an open-source container orchestration tool that allows
            administrators to automate the configuration and deployment of
            development environments in the cloud.
          </p>
          <br />
          <p>
            Each development environment within Armada exists as a set of
            containers that exposes an Integrated Development Environment (IDE)
            and all its necessary dependencies to developers via their browsers.
            Armada's architecture is self-hosted on an administrator's Amazon
            Web Services (AWS) account and is entirely managed from a dashboard
            in the browser.
          </p>
          <br />

          <h3>1.2 Understanding the Problem Space</h3>
          <p>
            Before diving into Armada's feature set, it's important to highlight
            the difficulties of setting up and maintaining developer
            environments. Common challenges include configuration, dependency
            management, and resource availability.
          </p>
          <figure>
            <img
              src="assets/config_overload_dep_management_resource_aval.png"
              class="case-study-image-medium"
              alt="Three images representing configuration overload, dependency management, and resource availability."
            />
          </figure>
          <br />

          <h4>1.2.1 Configuration Overload</h4>

          <p>
            Developers have no shortage of productivity-enhancing tools from
            bundlers to compilers to linters to transpilers. These tools support
            a diverse set of use cases across an ever-expanding number of
            disciplines, often exposing a configuration file for users to
            fine-tune settings.
          </p>

          <br />

          <p>
            While the flexibility of customizing a tool to address individual
            use cases may seem like an ideal solution, repeating this process
            across multiple tools can lead to a constellation of fragile
            dependencies and lengthen the amount of time that it takes to get
            started on a project. Furthermore, some tools offer so much
            flexibility that their configuration files can require their own
            specialists to decipher, all of which can easily lead to decision
            fatigue. Rather than outlining your core feature set, you'll spend a
            non-trivial amount of time level-setting your linter and fiddling
            with your formatter.
          </p>

          <br />

          <h4>1.2.2 Dependency Management</h4>
          <p>
            Most applications rely on other publically-available tools,
            frameworks, and libraries. Reusing the work of others removes
            redundancy from workflows and greatly accelerates the speed with
            which software can be developed. However, using these tools comes
            with its own set of tradeoffs.
          </p>

          <br />

          <p>
            Almost all modern software is constructed in this way, which means
            that any project that an engineer might work on will have to contend
            not only with its immediate dependencies but also the dependencies
            that its dependencies introduce. While package management tools
            abstract much of this complexity away, developers are still left to
            deal with the fragility that arises from long chains of
            dependencies: upgrading a single dependency can break the entire
            chain or create a circular dependency.
          </p>

          <br />

          <h4>1.2.3 Resource Availability</h4>

          <p>
            Depending on the environment you're working in or the type of
            application you're attempting to construct, your workflow may
            require a significant amount of computational resources (i.e., CPU,
            RAM, GPU, etc.).
          </p>

          <br />

          <p>Such tasks include:</p>
          <ul>
            <li>
              Creating virtual environments on your local machine (i.e., VMWare,
              Docker, etc.).
            </li>
            <li>Utilizing compilers and test runners in "watch" mode.</li>
            <li>
              Running emulation software for specific deployment targets (i.e.,
              Android, iOS,watchOS, etc.).
            </li>
            <li>Compiling complex or large applications.</li>
            <li>Running one or more databases.</li>
          </ul>

          <br />

          <p>
            These computationally-intensive tasks increase the minimum hardware
            requirements needed to be able to do certain kinds of development
            work. Unfortunately, this hardware can be expensive, limiting access
            to the machines that can perform these tasks.
          </p>

          <br />

          <h3>1.3 Narrowing Our Focus: Education</h3>

          <p>
            Although these issues are commonplace, they're often most keenly
            felt by students just getting started, which means they're
            particularly challenging for their instructors as well.
          </p>
          <figure>
            <img
              src="assets/students_instructor.png"
              class="case-study-image"
              alt="Three students and an instructor."
            />
          </figure>
          <br />

          <h4>1.3.1 Students</h4>

          <p>
            For students who are just learning how to build software, the
            challenges of setting up a development environment can be
            frustrating at best and insurmountable at worst. A new student's
            time and effort are better spent on gaining fluency and comfort with
            core programming skills, such as being able to write valid code,
            understand syntax, efficiently parse error messages, work on the
            command line, and read documentation. Furthermore, time and
            attention are both finite, and students who have exhausted their
            mental resources in the setup phase of a lesson are less likely to
            complete the lesson itself.
          </p>
          <figure>
            <img
              src="assets/student-struggle.gif"
              class="case-study-image"
              alt="An animated image of a student learning to code with several questions."
            />
          </figure>

          <br />

          <h4>1.3.2 Instructors</h4>

          <p>
            From the perspective of those teaching software development,
            understanding precisely why a student's development environment
            isn't working correctly can be a time-consuming guessing game, and
            navigating version conflicts and configuration issues on a
            student-by-student basis is neither efficient nor scalable.
          </p>
          <figure>
            <img
              src="assets/instructor_challenges.png"
              class="case-study-image-medium"
              alt="An image with multiple icons representing computer issues that instructors face."
            />
          </figure>
          <br />

          <h2 class="h2">2. Supporting Students</h2>
          <br />

          <h3>2.1 One-by-One</h3>

          <p>
            In a typical classroom setting, each student's development
            environment is their local machine. When issues with dependencies or
            configuration arise, the instructor needs to troubleshoot them on
            the individual machines where they're appearing. In the best case,
            an issue may be so common that the instructor can document how to
            resolve the problem and leave said resolution to students. An
            alternative is that the instructor can manually intervene to prevent
            the issue from arising again. In any event, dealing with the
            recurring issues of configuration and dependency management across
            many individual machines is burdensome.
          </p>
          <figure>
            <img
              src="assets/instructor_options.png"
              class="case-study-image"
              alt="A book representing a manual and an image representing a 1 to 1 relationship."
            />
          </figure>
          <br />

          <h3>2.2 One for All, All for One</h3>

          <p>
            What if an instructor were able to guarantee that every student had
            access to the same hardware and software? Dealing with a single
            configuration would significantly reduce the complexity of
            supporting a group of students. But, how could this be done?
          </p>

          <br />

          <p>
            Rather than purchasing a new computer for every student, an
            instructor might consider <strong>virtualization</strong>:
            configuring multiple, isolated environments for students all from
            one server.
          </p>

          <br />

          <h4>2.2.1 Virtualization</h4>
          <figure>
            <img
              src="assets/virtualization.png"
              class="case-study-image"
              alt="An large computer being divided into three smaller computers."
            />
          </figure>

          <p>
            According to
            <strong
              ><a
                href="https://www.ibm.com/cloud/learn/virtualization-a-complete-guide"
                >International Business Machines (IBM)</a
              ></strong
            >, "Virtualization uses software to create an abstraction layer over
            computer hardware that allows the hardware elements of a single
            computer—processors, memory, storage and more—to be divided into
            multiple virtual computers, commonly called virtual machines (VMs).
            Each VM runs its own operating system and behaves like an
            independent computer, even though it is running on just a portion of
            the actual underlying computer hardware." In some instances, the
            computer running the virtualized environments is referred to as the
            <strong>host</strong> or <strong>host machine</strong>, while the
            virtualized environments themselves are referred to as
            <strong>guests</strong> or <strong>guest operating systems</strong>.
          </p>

          <br />

          <h4>2.2.2 The Upside</h4>

          <p>
            One of the key features of virtualization is the ability to create
            an <strong>image</strong>, a snapshot of a computer's operating
            system, its files, and its overall state. After an image is created,
            it can serve as the basis for an arbitrary number of virtual
            machines. For instance, an image could contain all of the
            prerequisite files, software, and dependencies needed to perform
            tasks for a given class. These images could also be used to restore
            a given virtual machine to the desired state should something go
            awry.
          </p>
          <figure>
            <img
              src="assets/images_virtual_machines.png"
              class="case-study-image"
              alt="An image being applied to 9 individual virtual machines."
            />
          </figure>
          <br />

          <p>
            With this approach, an instructor could configure a single,
            functional workspace to distribute to each student. If changes or
            updates need to be made, the instructor could simply create a new
            image, ensuring that solving a configuration problem for a single
            student would solve the same configuration problem for all students.
          </p>

          <br />

          <h4>2.2.3 The Downside</h4>

          <p>
            The prospective overhead in terms of time and money is significant.
            The kinds of servers capable of hosting enough VMs for a classroom
            of students are not cheap, and managing them becomes a job in and of
            itself. Additionally, this is not a scalable solution: adding
            capacity means upgrading existing hardware or purchasing new
            hardware altogether. The server is also a single point of failure.
            If it goes down, no student can access their environment.
          </p>
          <figure>
            <img
              src="assets/cost_management_expansion_spof.png"
              class="case-study-image"
              alt="Various icons indicating cost, management, expansion, and a single point of failure."
            />
          </figure>
          <br />

          <h3>2.3 The Cloud: A Possible Solution</h3>

          <p>
            An ideal solution would abstract away the problems of hardware
            without being cost-prohibitive while ensuring that issues resolved
            for one student would be resolved for all students. Fortunately,
            modern cloud technologies make such a solution possible. By offering
            centrally-managed, virtualized environments to students from the
            cloud, it's possible to affordably offer a set of virtual machines
            that can be configured and maintained from a single template and
            served to an arbitrary number of students.
          </p>

          <br />

          <h2 class="h2">3. Cloud Deployments</h2>
          <figure>
            <img
              src="assets/cloud_raining_computers.png"
              class="case-study-image-small"
              alt="A cloud raining computers."
            />
          </figure>

          <br />

          <h3>3.1 What are Cloud Environments?</h3>

          <p>
            Cloud environments are a type of third-party service that provides
            on-demand access to networking and computational resources. Unlike
            on-premises data centers, which require purchasing and configuring
            new hardware to expand capacity, cloud environments can easily scale
            with demand. To add capacity in a cloud environment, users simply
            need to make a request to the cloud provider. In many cases, the
            provisioning of capacity can be managed automatically to adjust the
            number of resources according to the user's needs.
          </p>

          <br />

          <h3>3.2 A Modular, Replicable Approach</h3>

          <p>
            In a cloud environment, instructors no longer have to concern
            themselves with hardware. They can dedicate their time and attention
            to configuring a single environment exactly as they want it before
            deploying it as many times as they need.
          </p>

          <br />

          <h3>3.3 A Identifying Inefficiencies</h3>

          <p>
            This solution has a significant drawback, however, because the
            minimum memory and CPU capacity for VMs offered by cloud providers
            is still well beyond what most development environments require.
            Most of the time students won't use the full capacity of either the
            machine's CPU or its memory, which means that instructors are paying
            for more resources than they're actually using. For this reason,
            many developers opt to further virtualize their environments with
            the help of <strong>containers</strong>.
          </p>
          <figure>
            <img
              src="assets/memory_cpu_cost.png"
              class="case-study-image"
              alt="Three icons representing memory, CPU, and cost."
            />
          </figure>

          <br />

          <h3>3.4 Containerization</h3>
          <figure>
            <img
              src="assets/memory_cpu_cost_containers.png"
              class="case-study-image"
              alt="Three icons representing memory, CPU, and cost with an arrow pointing to four containers."
            />
          </figure>

          <p>
            Containers use virtualization but are not fully-fledged virtual
            machines on their own. Instead, containers are applications that are
            bundled along with their dependencies using software such as Docker.
          </p>

          <br />

          <p>
            Rather than virtualizing an entire machine including its hardware
            like a VM, containers instead virtualize the OS, allowing them to
            stay much lighter-weight than VMs & unaware of the underlying
            systems they are running on.
          </p>

          <br />

          <p>
            One side effect of this lighter-weight is that containers aren't
            meant to persist for long periods of time. Instead, they're designed
            to be created, used, and then destroyed. Due to their ephemeral
            nature, containers often present unique challenges when attempting
            to persist data.
          </p>

          <br />

          <h4>3.4.1 An Aside: Docker</h4>

          <p>
            Docker is an open-source platform for creating, developing, and
            managing containers. Within the Docker ecosystem, container images
            are created via a <strong>Dockerfile</strong>. Dockerfiles enable
            developers to configure how a container is constructed, including
            specifying a base image that can be extended. These images are
            consumed by the Docker Engine which is a runtime environment that
            enables containers to be run locally on a developer's machine.
          </p>
          <figure>
            <img
              src="assets/dockerfile_to_dockerengine.png"
              class="case-study-image"
              alt="An image representing a sequence of events from creating a dockerfile, making a docker image, and running a docker container on the docker engine."
            />
          </figure>

          <br />

          <h3>3.5 The Challenges of Managing the Cloud</h3>
          <figure>
            <img
              src="assets/octopus.png"
              class="case-study-image"
              alt="An octopus juggling several shipping containers."
            />
          </figure>

          <p>
            In order for an instructor to take advantage of containerization in
            the cloud to create and replicate developer environments, they would
            need to do the following:
          </p>

          <ul>
            <li>Choose a cloud provider.</li>
            <li>
              Learn about the different services available through that provider
              or identify an abstracted solution that works across cloud
              providers (i.e., Hashicorp's Terraform).
            </li>
            <li>
              Provision and connect the various services needed to create
              containerized environments and make them accessible to students.
            </li>
            <li>
              Manage security and permissions to ensure that students (and only
              students) have access to what they need.
            </li>
            <li>
              Develop a scalable process to create and destroy these
              environments.
            </li>
          </ul>

          <br />

          <p>
            Performing each of these steps requires a significant amount of
            expertise, time, and effort. Fortunately, there are several
            commercially-available products that achieve these goals without
            requiring the instructor to be a cloud expert.
          </p>

          <br />

          <h2 class="h2">4. Existing Solutions</h2>

          <p>
            There are a handful of products that abstract away the issues of
            creating and managing developer environments at scale within the
            cloud. These are Coder, Gitpod, and GitHub Codespaces.
          </p>
          <figure>
            <img
              src="assets/existing_solutions.png"
              class="case-study-image"
              alt="Logos for Coder, Gitpod, and GitHub Codespaces."
            />
          </figure>

          <br />

          <h3>4.1 Clarifying Criteria</h3>

          <p>
            While each of these individual solutions have their own particular
            strengths, they also come with their own set of tradeoffs. We
            assessed these solutions against several key criteria:
          </p>
          <figure>
            <img
              src="assets/criteria.png"
              class="case-study-image"
              alt="Various images representing ease of setup, ease of use, multi-IDE support, custom templates, the ability to self-host, and cost."
            />
          </figure>

          <ul>
            <li>
              <strong>Ease of Setup</strong>: How difficult is it to get a
              working copy of this product on your own system?
            </li>
            <li>
              <strong>Ease of Use</strong>: How difficult is it to configure and
              use the features offered by this product?
            </li>
            <li>
              <strong>Multi-IDE Support</strong>: Does this product let you
              choose which IDE to use (i.e., VS Code, JetBrains, etc.)?
            </li>
            <li>
              <strong>Custom Templates</strong>: Does this product provide the
              ability to customize the environment and its dependencies to meet
              my needs?
            </li>
            <li>
              <strong>Self-Hostable</strong>: Could you deploy this product on
              an architecture of your own?
            </li>
            <li>
              <strong>Cost</strong>: What are the upfront and recurring costs
              for a given solution? Do I have to pay a flat price, a price per
              user, or is there a tiered system involved?
            </li>
          </ul>

          <br />

          <h3>4.2 Tangible Tradeoffs</h3>

          <br />

          <h4>4.2.1 Coder</h4>
          <p>
            Coder is light, fast, flexible, and offers all of the core
            functionality a developer expects in an IDE. However, getting it up
            and running on your own system can be challenging. Whether you're
            using their self-hosted platform or their enterprise product,
            there's a fair number of obstacles that require manual intervention
            creating a higher barrier of entry. That being said, Coder provides
            a reasonably priced platform which charges $35 per user per month.
          </p>

          <br />

          <h4>4.2.2 Gitpod</h4>
          <p>
            Gitpod offers an extensive feature set, and aside from a longer
            startup time, it's also quite fast and flexible. Like Coder, the
            installation process doesn't always work right out of the box, and
            it can be challenging to get a working copy of the free-tier product
            on a local machine. The full range of features offered by Gitpod can
            make it challenging to configure, making the learning curve rather
            steep for all of the bells and whistles that it provides.
          </p>

          <br />

          <h4>4.2.3 GitHub Codespaces</h4>
          <p>
            Due to its seamless integration with the GitHub platform, GitHub
            Codespaces offers an easy-to-use, turnkey experience that allows
            developers to get started quickly. However, GitHub Codespaces limits
            users to operating only on their platform through the use of an
            instance of VS Code. Additionally, the environments provided by
            GitHub Codespaces can be customized to meet individual needs, but
            the cost of each environment is the most out of any of the available
            solutions.
          </p>

          <br />

          <p>
            Each of these products stand on their own merit, but it became clear
            that there was one thing they all had in common: all three were
            designed with a seasoned developer in mind as their end user, and
            were largely built to accommodate the needs of enterprises.
          </p>

          <br />

          <p>That's where <strong>Armada</strong> comes in…</p>

          <br />

          <h3>4.3 An Education-First Approach</h3>

          <p>
            We built Armada to provide an easy-to-use, low-cost option that was
            tailor-made for the education space.
          </p>

          <br />

          <p>
            Some key features which differentiate Armada from existing solutions
            include:
          </p>

          <ul>
            <li>
              <strong>Target Audience</strong>: Armada was built with education
              in mind and aimed to be powerful enough to serve a broad
              cross-section of instructors and students without being
              technically burdensome.
            </li>
            <li>
              <strong>Ease of Use</strong>: Administrators can easily create and
              manage development environments from Armada's UI. After
              authenticating, all students need is a link to their environment
              to access it via their browsers.
            </li>
            <li>
              <strong>Cost</strong>: Armada's only cost is the cost incurred
              from running its underlying resources on the cloud.
            </li>
            <li>
              <strong>System Ownership</strong>: Armada is deployed to an
              instructor's own AWS account, allowing them to maintain full
              control over the system and the data it generates.
            </li>
            <li>
              <strong>Extensibility</strong>: Armada is fully open-source. Any
              sufficiently technical instructor is free to extend the system to
              suit their particular needs.
            </li>
          </ul>

          <br />

          <p>
            Below is a comparison of each product, including their open-source
            and paid offerings.
          </p>
          <figure>
            <img
              src="assets/solutions_chart.png"
              class="case-study-image"
              alt="A chart comparing Gitpod, Coder, GitHub Codespaces, and Armada based on the previously defined criteria."
            />
          </figure>

          <br />

          <h2 class="h2">5. Armada</h2>

          <br />

          <h3>5.1 Recap</h3>

          <br />

          <h4>5.1.1 Challenges</h4>

          <p>
            Configuring a development environment presents several challenges,
            which include:
          </p>

          <br />

          <h5>For Students</h5>
          <ul>
            <li>
              Knowledge of complicated environment configuration and dependency
              management.
            </li>
            <li>
              Access to hardware capable of carrying out common developer tasks
              and running supporting software.
            </li>
          </ul>

          <br />

          <h5>For Instructors</h5>

          <ul>
            <li>
              Navigating between a compounding number of student hardware
              configurations, operating systems, software versions, and
              experience levels.
            </li>
          </ul>

          <br />

          <h4>5.1.2 Goals</h4>

          <p>
            In response to these challenges, we developed Armada with the
            following goals in mind:
          </p>

          <ol>
            <li>Create easy-to-use development environments for students.</li>
            <li>
              Make it easy for instructors to manage and deploy development
              environments.
            </li>
            <li>
              Provide the ability to scale to meet student and instructor
              demand.
            </li>
            <li>Minimize costs for instructors.</li>
          </ol>

          <br />

          <h3>5.2 But First, A Demo</h3>

          <br />

          <h3>5.3 The Roadmap</h3>
          <figure>
            <img
              src="assets/roadmap_icon.png"
              class="case-study-image-small"
              alt="A gradient picture of a treasure map with an X marking the end of a path."
            />
          </figure>

          <p>
            With this information in hand, there were eight key milestones that
            we needed to achieve in order to create, manage, and serve
            development environments that instructors and students could make
            use of, including:
          </p>

          <ol>
            <li>Containerizing a workspace.</li>
            <li>Provisioning cloud infrastructure.</li>
            <li>Deploying a single workspace.</li>
            <li>Deploying several workspaces.</li>
            <li>Accessing workspaces from dedicated URLs.</li>
            <li>Persisting workspace data.</li>
            <li>
              Establishing relationships between user data entities and
              providing a user interface for instructors and students.
            </li>
            <li>Providing user authentication.</li>
          </ol>

          <br />

          <h3>5.4 Containerizing a Workspace: Developing at Scale</h3>

          <br />

          <h4>5.4.1 Choosing an Environment</h4>
          <figure>
            <img
              src="assets/gitpod_vs_codeserver.png"
              class="case-study-image"
              alt="Two rectangles, each with a logo inside, for Gitpod and Coder representing a container with a coding environment."
            />
          </figure>

          <p>
            Creating the coding environment itself wasn't the primary focus of
            building Armada. Fortunately, a number of freely available, open
            source solutions already existed.
          </p>

          <br />

          <p>
            As mentioned previously, both Gitpod and Coder offer open-source
            versions of their paid platforms and products including
            containerized versions of VS Code, a popular, open-source code
            editor created by Microsoft. These containers bundle VS Code with
            its dependencies, exposing it via a network port which can be
            accessed from a browser. While either solution could have been used
            as the basis for Armada's workspaces, there were significant
            tradeoffs for each.
          </p>

          <br />

          <p>
            Even in its open-source form, Gitpod offers a number of extensible
            configuration and customization features in addition to several
            integrations. However, this comes at the cost of both speed and
            size. At the time of Armada's initial build, Gitpod's container was
            roughly 7 gigabytes (GB), and its typical start time ranged from
            5-10 minutes. By contrast, Coder's container (code-server) was less
            than a GB and offered all of the functionality we would need to
            provide an IDE to students, while being both lightweight and fast
            with load times under 20 seconds. However, the container is a
            significantly more limited version of their enterprise product,
            disabling many key features including groups, custom templates,
            isolated runners, and high availability.
          </p>

          <br />

          <p>
            Given that one of our main goals was to keep costs down, we chose to
            use the Coder image as our base since it would allow us to provision
            more instances of the workspace container per server than the GitPod
            image.
          </p>

          <br />

          <p>
            We now had containers that would run on our local machines and were
            able to provide individualized workspaces that could be accessed in
            the browser. Our next challenge would be running a single container
            on a server in the cloud.
          </p>

          <br />

          <h3>5.5 Gaining Access to the Cloud</h3>

          <br />

          <h4>5.5.1 Starting from Scratch</h4>

          <p>
            In order to begin building Armada, we needed to make a key
            architectural decision: would we focus on a single cloud provider
            (<strong>cloud native</strong>) or ensure that Armada works across
            all platforms (<strong>cloud agnostic</strong>)? Making this
            decision would have real-world implications for the reliability,
            scalability, and maintenance cost of our application.
          </p>

          <br />

          <h5>Cloud Native</h5>

          <p>
            "Cloud Native" is a development philosophy that centers around
            building applications with technologies that are "native" to a
            specific cloud service provider. One of the most useful features of
            a cloud-native approach is that it allows developers to avoid
            undifferentiated heavy lifting, meaning that the operational burden
            of managing IT services is delegated to the cloud provider. This
            allows developers to focus on building the application's core
            features. However, by limiting the application to one cloud service
            provider, the developers become locked into that provider's
            framework, sacrificing the freedom to move their application to a
            different cloud provider's platform without substantial rewrites.
          </p>
          <figure>
            <img
              src="assets/cloud_native.png"
              class="case-study-image"
              alt="Three clouds representing several cloud providers includign Azure, Google Cloud, and AWS."
            />
          </figure>
          <br />

          <h5>Cloud Agnostic</h5>

          <p>
            A cloud-agnostic approach revolves around designing applications
            that can be deployed to any cloud environment using open-source
            technologies. Building cloud applications in this way gives
            developers the ability to avoid vendor lock-in.
          </p>
          <figure>
            <img
              src="assets/cloud_agnostic.png"
              class="case-study-image-small"
              alt="One big cloud representing developing for all cloud providers simultaneously."
            />
          </figure>
          <br />

          <p>
            The additional flexibility offered by writing applications to work
            on any cloud provider is not without tradeoffs. It is easy to garner
            the impression that cloud agnosticism means that a single code base
            will work on all cloud platforms, but that is not the actual case.
            In reality, a fair amount of work has to be done to adapt the
            application to run on each cloud provider's environment.
          </p>

          <br />

          <p>
            Additionally, using open-source technologies intended to support
            cloud agnosticism can add significantly more complexity. Developer
            responsibilities could expand to include activities such as applying
            security patches, updating virtual machines' operating systems, and
            managing backups. Unfortunately, these duties take valuable time
            away from other tasks, such as creating new features or resolving
            user issues. While the cloud-agnostic approach is meant to improve
            flexibility and portability, it often introduces significant
            logistical and maintenance overhead.
          </p>

          <br />

          <h5>Amazon Web Services (AWS)</h5>

          <p>
            After considering the advantages and disadvantages of each
            architectural approach, we decided to take a cloud-native approach
            and host our application on Amazon. AWS provided several services
            that would enable us to focus on development instead of system
            administration.
          </p>
          <figure>
            <img
              src="assets/aws_logo.png"
              class="case-study-image-small"
              alt="The AWS logo."
            />
          </figure>
          <br />

          <p>
            In addition, AWS has a vast tooling ecosystem that integrates
            seamlessly with the platform,providing a cohesive developer
            experience. AWS exposes a multitude of different tools including the
            Command Line Interface (CLI), Software Development Kit (SDK), and
            Cloud Development Kit (CDK), which greatly improved our ability to
            prototype and iterate.
          </p>

          <br />

          <h4>5.5.2 Spike then Automate</h4>

          <p>
            As we set out to construct Armada, our primary focus was on creating
            a consistent, reproducible environment that could be easily shared
            amongst our team and inform a deployment strategy for our future
            users.
          </p>
          <figure>
            <img
              src="assets/sdk_cdk.png"
              class="case-study-image"
              alt="Logos for AWS SDK and AWS CDK."
            />
          </figure>

          <br />

          <p>
            Amazon enables the programmatic provisioning of resources through
            its Infrastructure-as-Code (IaC) product, CloudFormation.
            CloudFormation enables developers to request and customize any AWS
            resource using files written in either YAML or JSON. However, these
            files are often tedious to maintain and require an extensive,
            granular focus on specifying roles, permissions, and dependencies.
          </p>

          <br />

          <p>
            To make it easier to specify the correct configuration, Amazon
            provides an abstraction on top of CloudFormation known as the Cloud
            Development Kit (CDK), which allows developers to create
            CloudFormation templates and customize resources using one of
            several prominent programming languages.
          </p>

          <br />

          <p>
            Through our use of the CDK, we were able to create, share, and
            incrementally extend our architecture with ease. This was important,
            as Armada's cloud native nature required that it be built from the
            ground up with the benefits of the cloud in mind. We needed to
            understand how specific pieces of the architecture would interact
            and communicate and the only way to do that was through the platform
            rather than developing Armada locally and viewing the cloud as a
            deployment target.
          </p>

          <br />

          <h3>5.5 Deploying a Single Workspace</h3>

          <br />

          <h4>5.5.1 Workspaces in Motion</h4>

          <p>
            With our workspace container squared away, we needed a viable method
            for constructing, serving, and managing our containerized developer
            environments in the cloud.
          </p>

          <br />

          <h4>5.5.2 Walk, Then Run</h4>

          <p>
            In order to understand how our containers would interact with their
            hosts, we needed to be able to focus on the simplest iteration of
            our product: A single unmanaged container deployed in a cloud
            environment. For this task, we made use of AWS's Elastic Cloud
            Compute (EC2) service, which provides and manages virtual servers,
            which we could then use as hosts for workspaces. Since workspaces in
            Armada are defined as Docker images, we began by installing the
            Docker Engine on an EC2 instance and configured that container to
            open a network port so that it would be accessible from an outside
            connection.
          </p>
          <figure>
            <img
              src="assets/nginx_codeserver.png"
              class="case-study-image"
              alt="Two rectangles representing linked nginx and code-server containers."
            />
          </figure>

          <br />

          <p>
            Overall, this process didn't offer much in the way of automation and
            would not have been practicable at scale. While our initial focus
            was on a single environment, it was important to consider the need
            for the ability to deploy multiple environments simultaneously in
            the future.
          </p>

          <br />

          <h4>5.5.3 A Symphony of Software</h4>

          <p>
            Automating the deployment, management, scaling, and lifecycle of
            containerized applications deployed across multiple machines, also
            known as <strong>container orchestration</strong>, is a common issue
            in the world of software development. The Docker Engine on its own
            is not sufficient to meet these challenges at scale. As such we
            looked to several different open-source and cloud native solutions,
            including Kubernetes, Docker Swarm, and Amazon's Elastic Container
            Service (ECS).
          </p>
          <figure>
            <img
              src="assets/orchestration_tools_chart.png"
              class="case-study-image"
              alt="A comparison chart of each of the container orchestration tools (i.e., Kubernetes, Docker Swarm, and ECS)."
            />
          </figure>

          <br />

          <h5>Kubernetes</h5>

          <p>
            Kubernetes is a mature, actively-maintained, open-source technology.
            The richness of its feature set was highly attractive, but those
            features also came with a proportionate level of complexity. We
            concluded that since we would only need a small subset of the
            functionality provided by Kubernetes, it would be better to use a
            less powerful technology that addressed our needs.
          </p>

          <br />

          <h5>Docker Swarm</h5>

          <p>
            Docker Swarm is a part of the Docker Engine and therefore has far
            fewer dependencies than Kubernetes. Additionally, the time required
            to learn how to deploy a cluster of workers managed by Docker Swarm
            is much less than what would have likely been needed to use
            Kubernetes. However, it is not without its drawbacks. Using Docker
            Swarm would have required the Armada team to construct and implement
            complex mechanisms for managing container logging, handling
            container health checks, and scaling the underlying architecture
            based on demand (i.e., controlling the number of provisioned EC2
            instances).
          </p>

          <br />

          <h5>Elastic Container Service (ECS)</h5>

          <p>
            The Elastic Container Service (ECS) provided by Amazon struck the
            right balance between a rich feature set and ease of use. ECS
            allowed us to provision a managed cluster of containers via Amazon's
            Cloud Development Kit (CDK). Furthermore, we were able to configure
            ECS to spin up containers or tear them down as needed without
            burdening the Armada codebase with the logic required to perform
            orchestration. Additionally, ECS integrates with other AWS services
            and grants us the ability to autoscale both containers and the
            hardware required to host those containers. It also provides a
            mechanism for monitoring and logging containers, creating the
            ability to recover crashed student workspaces without requiring the
            instructor to intervene.
          </p>

          <br />

          <h4>5.4 Key Terminology</h4>

          <p>
            In order to fully grasp the way Armada's workspaces eventually
            functioned within ECS, it's necessary to review some key
            terminology.
          </p>

          <br />

          <p>
            ECS provides the ability to create containers via
            <strong>task definitions</strong>, which are analogous to how a
            <strong>Docker image</strong> is derived from a
            <strong>Dockerfile</strong>. Container images are published to an
            image registry such as Docker Hub or Amazon's own registry called
            the Elastic Container Registry (ECR). In addition to specifying what
            images to use, task definitions can configure different parameters
            for a container such as port mapping, data volumes, and memory
            usage.
          </p>

          <br />

          <p>
            After a container or set of containers has been defined as a task
            definition, ECS allows you to run these containers as a
            <strong>task</strong>. A group of tasks running together is called a
            <strong>service</strong>. Services allow for finer-grained control
            over the group of tasks, including the desired count and percentage
            of tasks to maintain in a running status along with networking
            configuration. Finally, a <strong>cluster</strong> is a group of
            tasks or services that together encompass an entire application.
          </p>

          <br />

          <h4>5.5 A Task at a Time</h4>
          <figure>
            <img
              src="assets/one_task.png"
              class="case-study-image-small"
              alt="A series of squares containing a single code-sever container in an ECS task."
            />
          </figure>

          <p>
            In its initial form, Armada utilized individual tasks and task
            definitions to pull a custom image from Docker Hub that included
            code-server, Coder's open-source VS Code image described above. This
            allowed us to run and deploy our developer environments as
            proof-of-concept and enabled individual workspaces to be accessed
            via the Internet.
          </p>
          <figure>
            <img
              src="assets/one-task-to-rule-them-all.gif"
              class="case-study-image"
              alt="An animation of the process of creating a development environment from a single, isolated task."
            />
          </figure>

          <br />

          <h4>5.6 Moving Forward</h4>

          <p>
            With this approach, we gained the ability to provide isolated
            developer environments in the cloud. However, running workspaces as
            individual tasks did not give us fine-grained control over the
            health and monitoring of their containers. Therefore, we began
            searching for a way to manage multiple workspaces in a way that
            would scale without introducing fragility.
          </p>
          <figure>
            <img
              src="assets/reliability_scalability.png"
              class="case-study-image-medium"
              alt="A stethoscope with a red circle and a line through it representing a lack of reliability and a wifi image with a red cicle and a line through it representing a lack of scalability."
            />
          </figure>

          <br />

          <h3>5.6 Deploying Multiple Workspaces</h3>

          <p>
            In order for Armada to operate as a fully-fledged product, we needed
            to be able to serve an arbitrary number of users simultaneously.
            Therefore, we needed a method for not only managing the lifecycle
            and health of our developer environments but for scaling the
            infrastructure running those containers.
          </p>

          <br />

          <h4>5.6.1 The Problem with Tasks</h4>

          <p>
            By operating exclusively with tasks, we weren't able to respond to
            any unexpected errors within our containers, which meant that our
            tasks could stop without any recourse. Additionally, tasks did not
            offer an option to configure networking, which would become
            extremely important when we set out to match the correct task to the
            correct student workspace. Eventually, we concluded that we would
            need ECS services to meet our goals.
          </p>

          <br />

          <h4>5.6.2 A "Healthy" Alternative</h4>

          <p>
            Services enable ECS to automate the monitoring and management of
            containers. ECS performs health checks by making requests to a
            predefined URL which replies to ECS with a 200 response if the
            service is perfectly operational. If a container is deemed
            "unhealthy", ECS will automatically destroy and replace the
            containers defined by the tasks in the service.
          </p>
          <figure>
            <img
              src="assets/endpoint_response_unhealthy.png"
              class="case-study-image-small"
              alt="Three images representing an endpoint, a healthy 200 response, and an unhealthy container."
            />
          </figure>

          <br />

          <p>
            In the case of Armada, we only needed to run one task per service
            for each student's workspace. As an added benefit, this
            configuration provided us with a method to start and stop individual
            workspaces by updating the number of running tasks for a given
            service from zero to one task and vice-versa.
          </p>
          <figure>
            <img
              src="assets/one_service.png"
              class="case-study-image-small"
              alt="Multiple squares containing an ECS service which contains an ECS task."
            />
          </figure>
          <br />

          <p>
            With services in place, we needed to address an underlying issue
            with how the infrastructure for our ECS cluster was being allocated.
            Although ECS manages individual services and tasks, the actual
            containers run on individual EC2 instances which have a finite
            amount of available resources, most importantly memory (i.e., RAM).
            Luckily, AWS provides a method for creating a pool of resources that
            can scale horizontally with demand known as an autoscaling group
            (ASG).
          </p>

          <br />

          <h4>5.6.3 To Infinity and Beyond</h4>

          <p>
            We defined an autoscaling group for the EC2 instances that would act
            as hosts for our workspace containers. We configured this
            autoscaling group to add capacity based on the amount of memory
            reserved for each individual service. If the memory reserved for all
            tasks hosted on an individual EC2 instance exceeded this reserved
            bound of its total memory, the autoscaling group would instantiate a
            new EC2 instance to accommodate the additional demand. This same
            mechanism enabled us to automatically eliminate an EC2 instance if
            the resources are idle.
          </p>
          <figure>
            <img
              src="assets/cluster-autoscaling.gif"
              class="case-study-image"
              alt="An animation representing a cluster of EC2 instances scaling based on memory reservation."
            />
          </figure>

          <br />

          <h4>5.6.4 Look Who's Scaling Now</h4>
          <figure>
            <img
              src="assets/service-autoscaling.gif"
              class="case-study-image"
              alt="An animation representing services being placed in the most efficient location based on memory availability."
            />
          </figure>

          <p>
            With workspaces now defined as tasks under management by ECS
            services, we were able to easily turn workspaces on and off as well
            as manage unexpected failures within the workspaces themselves. We
            also gained the ability to scale EC2 instances to precisely meet the
            needs of running workspaces without wasting overhead. Services also
            offered one additional benefit that allowed us to solve a problem
            with providing workspaces to students that we would not have been
            able to easily address otherwise: Networking.
          </p>

          <br />

          <h3>5.7 Routing</h3>

          <br />

          <h4>5.7.1 From Port to Port</h4>

          <p>
            Up until this point, we'd been deploying individual workspaces on
            separate EC2 instances, because we'd hardcoded the container ports
            used in our task definitions. This was not the most efficient way to
            use EC2 instances, since each EC2 instance has enough resources to
            host multiple workspaces simultaneously. However, enabling multiple
            services to reside on the same host added significant complexity,
            because each successive workspace would need to guarantee that the
            ports it exposed on the host were not in use by another process or
            workspace. It turns out that this is quite a common hurdle when
            deploying containers on ECS.
          </p>

          <br />

          <h4>5.7.2 Added Complexity: A Deep Dive</h4>

          <p>
            Containers essentially operate as isolated virtual machines that
            share the underlying resources of their hosts rather than deploying
            a guest operating system per container. As such, containers maintain
            their own set of port mappings and settings. When we define a
            container, we're able to determine which ports on our host operating
            system (i.e., our actual computer) map to those within the container
            itself. We can either define a set port for the container to use
            (<strong>static port mapping</strong>) or allow the host operating
            system to dynamically choose a port based on which ports are
            available (<strong>dynamic port mapping</strong>).
          </p>

          <br />

          <h5>Static Port Mapping</h5>

          <p>
            If we relied on static port mapping, we could not deploy a container
            using the same host ports that were being used by another container.
            For example, if we have a task definition with a host port of 5000
            and a container port of 8080, we can't launch another ECS task that
            uses the same host port of 5000.
          </p>
          <figure>
            <img
              src="assets/static-port-mapping.gif"
              class="case-study-image"
              alt="An animation representing representing static port mapping for a single container per EC2 instance."
            />
          </figure>

          <br />

          <p>
            In order to temporarily bypass this roadblock, we continued tearing
            down and deploying our infrastructure, deploying one workspace to
            each EC2 instance in our ECS cluster. This gave us some leeway to
            keep experimenting while we searched for a more viable solution.
          </p>

          <br />

          <h5>Elastic Load Balancing (ELB) and Dynamic Port Mapping</h5>

          <p>
            We eventually landed on a potential solution to our networking
            challenges with Elastic Load Balancing (ELB) by using it as a load
            balancer in front of our ECS cluster, serving as the entry point
            into our application.
          </p>
          <figure>
            <img
              src="assets/elastic-load-balancing.gif"
              class="case-study-image"
              alt="An animation representing dynamic port mapping enabled by an Application Load Balancer."
            />
          </figure>

          <br />

          <p>
            Out of the four different load balancing options offered by ELB, we
            selected the Application Load Balancer (ALB). The ALB integrates
            seamlessly with ECS and provides a few key features that helped us
            overcome several of the challenges imposed by static port mapping.
          </p>

          <br />

          <p>
            The ALB supports dynamic host port mapping, which would allow us to
            deploy multiple tasks on the same EC2 instance. In order to take
            advantage of this behavior, all we needed to do was update our task
            definitions to indicate that selecting a host port would be the
            ALB's responsibility. When the ALB encounters a task configured in
            this way, it automatically selects an available port from the
            ephemeral range on an EC2 Instance. However, this led to another
            challenge.
          </p>
          <figure>
            <img src="assets/dynamic-port-mapping.gif" class="case-study-image"
            alt="""An animation detailing how dynamic port mapping actually
            takes place." />
          </figure>

          <br />

          <h6>Unintended Consequences</h6>

          <p>
            Typically, a load balancer is used to distribute traffic across a
            fleet of horizontally-scaled servers. However, Armada's workspaces
            are stateful: each one "belongs" to a specific student. By default,
            ALBs use a round-robin routing algorithm, which ensures that traffic
            is routed to each of the load balancer's targets in an evenly
            distributed manner (i.e., one after the other). This meant that
            every time the ALB endpoint was hit, the incoming request would be
            forwarded to a completely different task, which would result in a
            student connecting to a random environment instead of the one
            dedicated to them, not the intended behavior.
          </p>
          <figure>
            <img
              src="assets/alb-round-robin.gif"
              class="case-study-image"
              alt="An animation demonstrating round robin routing."
            />
          </figure>

          <br />

          <h6>Segmenting Traffic: Target Groups</h6>
          <figure>
            <img
              src="assets/target-groups.gif"
              class="case-study-image"
              alt="An animation demonstrating the use of target groups to enable routing to specific containers."
            />
          </figure>

          <p>
            In order to overcome this issue, we chose to map each individual
            workspace to its own target group. A target group is a collection of
            one or more logical resources that can receive traffic from a load
            balancer, which, in turn, provides the ability to segment traffic to
            specific resources based on URL.
          </p>

          <br />

          <p>
            Application Load Balancers (ALBs) can attach listeners to each
            available port on which they expect to receive traffic (i.e., Port
            80). Each of these listeners contain one or more rules that define
            where a specific request should be routed. Typically, these pathways
            are routed to specific target groups based on the path contained
            within the URL used to reach the ALB.
          </p>

          <br />

          <p>
            In the case of Armada, we use our consistent naming structure (i.e.,
            cohort-course-student) to define the resource path for each
            workspace's unique URL, and each rule is then created and attached
            to the ALB listener when a new task is defined.
          </p>

          <br />

          <p>
            By taking advantage of this path-based routing structure alongside
            dynamic port mapping, we were able to maintain a one-to-one
            relationship between workspaces and routes. As a result, each
            workspace could be given a unique path that would enable it to be
            accessed from a single base URL. Each workspace was then linked with
            its own NGINX container, allowing us to rewrite the portion of the
            URL used for path-based routing and enabling each workspace to be
            addressed as though it were a standalone application.
          </p>
          <figure>
            <img
              src="assets/url-cut.gif"
              class="case-study-image"
              alt="An animation demonstrating removing the base url to address the underlying container."
            />
          </figure>
          <br />

          <h4>5.7.3 Looking Inward</h4>

          <p>
            With each of these pieces in place, we were able to successfully
            automate the distribution of our developer environments. We could
            efficiently host multiple environments on a single EC2 instance,
            scale to more EC2 instances if needed, and provide a consistent
            method for accessing the correct environment.
          </p>

          <br />

          <p>
            Now that our overarching infrastructure was largely solidified, it
            was time to turn our efforts inward and focus on providing a
            complete user experience.
          </p>

          <br />

          <p>
            First up, we needed to provide a reliable way for our instructors
            and students to persist their data irrespective of the lifecycle of
            their developer environments.
          </p>

          <br />

          <h3>5.8 Data Persistence</h3>

          <p>
            One of the major issues we faced as we were developing Armada was
            determining how to persist data. Containers are inherently
            stateless, so each development environment that exists in a
            container does not save user data when the container stops running
            or otherwise shuts down. In other words, any changes a student makes
            to a workspace would be lost if not for persistent storage, so we
            needed to find a way to save data beyond the life of the ECS
            container.
          </p>

          <br />

          <h4>5.8.1 Storage Wars</h4>
          <figure>
            <img
              src="assets/ebs_vs_efs.png"
              class="case-study-image"
              alt="Logos for AWS products including EBS, S3, and EFS."
            />
          </figure>

          <p>
            When using Docker containers locally, volumes are used to persist
            data. However, volumes can not be used in a straightforward manner
            within a cloud environment due to their distributed nature.
            Therefore, we needed a more sustainable approach to storing volumes
            on a remote host and matching data to the correct container upon
            startup. In order to accomplish this, we explored two major avenues
            - using the Elastic File System (EFS) or Elastic Block Storage (EBS)
            in conjunction with S3 buckets.
          </p>

          <br />

          <h5>Elastic Block Storage (EBS)</h5>

          <p>
            EBS is a service that creates a virtual hard drive that can be
            mounted to an EC2 instance and treated as a block device. Using EBS
            originally seemed like a great way to get read/write storage for the
            workspace off of the workspace's physical host. However, these
            volumes are typically tied to the lifecycle of their hosts,
            introducing more volatility than necessary. Turning off or
            destroying an EBS volume would mean losing all of the student's
            data. For us to be able to store user data written to the EBS
            volume, we would need to create an S3 bucket to save a snapshot of
            the data.
          </p>

          <br />

          <p>
            The process that we worked out for using EBS to persist user data
            was:
          </p>

          <ol>
            <li>A student creates a new workspace.</li>
            <li>
              We retrieve the latest snapshot of data stored in the S3 bucket
              that is unique to the user.
            </li>
            <li>
              We query the Elastic Container Service using Amazon's UUID for the
              new workspace to get the UUID of the EC2 host of that workspace.
            </li>
            <li>We attach the EBS volume to the EC2 host for the workspace.</li>
            <li>
              On workspace shutdown, we create a new snapshot of the EBS volume
              and overwrite the stale data in the S3 bucket. Then we detach and
              destroy the EBS volume along with the workspace.
            </li>
          </ol>
          <figure>
            <img
              src="assets/ebs-walkthrough.gif"
              class="case-study-image"
              alt="An animation of the steps taken to create volumes on EBS."
            />
          </figure>

          <br />

          <h6>Limitations</h6>

          <p>
            Once we were able to establish that it was technically possible to
            use EBS and S3 in this manner, we also found that there were a
            number of issues that made it a suboptimal solution. Using EBS/S3
            largely precluded us from being able to scale workspaces easily and
            efficiently. EBS mounts directly to a virtual server in much the
            same way that a USB drive can be plugged into your desktop, which
            meant that we would have to work out a way to programmatically
            determine what mount points were available on the workspace host,
            and how to tell the newly instantiated workspace where that volume
            could be found. Solving both of these problems would mean writing
            custom scripts for the EC2 host that could discover and provide that
            information to both AWS and the workspace on the fly, an approach
            that we regarded as fragile and difficult to manage. If we decided
            to use this solution to provide persistent storage, we likely would
            have been relegated to running a single workspace per EC2 instance.
          </p>
          <figure>
            <img
              src="assets/scale_complex_inefficiency.png"
              class="case-study-image"
              alt="Three images representing scale, complexity, and inefficiency."
            />
          </figure>

          <br />

          <p>
            One of our primary goals when building Armada was to have a system
            that would scale student workspaces efficiently, meaning that we
            would use the minimum amount of computational power required to
            provide a smooth user experience. We ultimately decided to abandon
            EBS/S3 as a way to save user data between sessions, and instead
            turned our attention to Amazon's Elastic File System (EFS).
          </p>

          <br />

          <h5>Elastic File System (EFS)</h5>

          <p>
            EFS is a serverless, cloud native storage service that provides an
            on-demand, scalable file system. Where EBS creates a virtual hard
            drive that can be mounted to a server, EFS acts instead as an
            extension of an operating system's file system. It allows for data
            to be stored without the need to maintain storage capacity because
            the file system will grow and shrink according to the needs of the
            application. EFS works by monitoring a specific directory and uses
            serverless functions to mirror changes made to files in that
            directory. As a result, data is persisted regardless of the state of
            the container or its host.
          </p>
          <figure>
            <img
              src="assets/workspaces_with_arrow.png"
              class="case-study-image"
              alt="A screenshot of Armada's dashboard highlighting the Create Workspace button being clicked."
            />
          </figure>

          <br />

          <p>
            With EFS, we could much more readily predict and control how a
            workspace would connect to its storage. We immediately saw this as a
            tool that could fit our project's needs, since being able to attach
            our storage directly to a workspace without having to care about the
            workspace's host was a significant advantage. However, we had some
            reservations about EFS's pricing model and cost when compared to
            EBS. In the end, EFS proved to be the best fit for our use case of
            saving data for each student workspace that fit seamlessly with ECS.
          </p>

          <br />

          <h6>Missed Connections</h6>

          <p>
            Despite its benefits, implementing EFS still had its complexities.
            Using the CDK, we were able to provision an instance of EFS with the
            required security groups and networking configuration. Our first
            effort to implement EFS as a workspace's storage mechanism involved
            creating a task definition for each student workspace where a
            specified EFS volume could either be created or retrieved on
            startup.
          </p>

          <br />

          <p>
            However, in order to successfully attach and utilize EFS within
            Armada, there were two key components that needed to be present.
            First, the specific folder or directory being used on EFS must exist
            within the EFS volume itself before it can be mounted to a given
            container. Next, each task definition for a container must specify a
            mount point for the EFS volume that will be attached when the
            container is created, enabling the location of the directory to be
            configured based on the container's needs.
          </p>

          <br />

          <p>
            To resolve this issue, we used AWS Lambda functions to create
            uniquely named directories that would contain the EFS volumes
            mounted for each individual workspace. AWS Lambda runs serverless
            functions in response to predefined events. In our case, the Lambda
            function for creating the EFS mount point is triggered whenever an
            instructor creates a new task definition for a specific workspace.
          </p>

          <br />

          <p>
            The directories created as mount points for EFS followed the naming
            convention of "cohortName-courseName-studentName/coder" and within
            the container definitions for each workspace, that directory was
            mapped to "/home/coder".
          </p>

          <br />

          <p>
            To summarize, the order of events for using Lambda in conjunction
            with EFS to run our workspaces was as follows:
          </p>
          <figure>
            <img
              src="assets/saving_files.gif"
              class="case-study-image"
              alt="An animation of files being saved to EFS."
            />
          </figure>

          <ol>
            <li>
              Create a task definition referencing a volume that is a uniquely
              named directory on EFS.
            </li>
            <li>
              Using Lambda, create the directory within EFS that the task
              definition references in its EFS volume configuration with the
              naming convention of cohortName-courseName-studentName.
            </li>
            <li>
              Run the task (workspace) with the EFS volume mounted to a
              container directory called "home/coder".
            </li>
          </ol>

          <br />

          <h4>5.8.2 Great Success</h4>

          <p>
            With a data persistence solution in hand, we were able to
            successfully save students' work from one session to the next. Now,
            students could be sure that their data would be there, regardless of
            any interruptions or failures.
          </p>

          <br />

          <p>
            Looking forward, we needed a way to expose all of these established
            resources to our instructors and students in a straightforward and
            intuitive way.
          </p>

          <br />

          <h3>5.9 Improving Communication</h3>
          <figure>
            <img
              src="assets/architecture_with_efs.png"
              class="case-study-image"
              alt="A picture of the current state of Armada's architecture."
            />
          </figure>

          <p>
            To provide communication between the different pieces of our
            architecture, the Armada team needed to give instructors the ability
            to programmatically communicate with each component and issue
            commands in a way that was intuitive and convenient. We needed to
            expose these methods to our end users so that they could manage and
            create workspaces without having to rely purely on the command line
            or interfaces established by AWS (i.e., Console or CLI). To achieve
            these goals, we began constructing a full-stack application that
            would eventually become the Armada application.
          </p>

          <br />

          <h4>5.9.1 The Armada Application</h4>

          <p>
            Armada's backend is an Express application written in TypeScript
            which acts as the central control hub, connecting each component of
            provisioned architecture to ensure that instructors can provision
            and manage student workspaces at scale. The application itself is
            containerized and deployed within the group of containers known as
            the ECS Cluster, which provides guarantees about its health and
            availability.
          </p>

          <br />

          <h4>5.9.2 The Software Development Kit (SDK)</h4>

          <p>
            In order to communicate with each piece of the architecture, we
            needed a structured interface with which to do so. Amazon offers a
            Software Development Kit (SDK) that provides a modular, class-based
            client for each resource that allows you to instantiate and send
            individual commands to perform common actions. Each command can be
            customized by defining properties on an `input` object. While
            performing each action in isolation is useful, Armada's needs
            continued to increase in complexity as its functionality was
            extended. By wrapping our feature set around the functionality
            defined within the SDK, the Armada team was able to encapsulate
            several isolated actions into singular endpoints, greatly
            simplifying an instructor's workflow.
          </p>

          <br />

          <p>
            For instance, when an instructor creates a workspace for a specific
            student, Armada performs the following actions under the hood using
            the SDK:
          </p>

          <ul>
            <li>
              Creates a task definition specific to the student, outlining the
              configuration of the requisite containers.
            </li>
            <li>
              Creates a target group for the student's workspace and attaches a
              rule to the listener on the ALB, allowing the workspace to receive
              traffic once it's operational.
            </li>
            <li>
              Creates a service specific to the student on ECS allowing its
              availability and health to be managed and monitored automatically.
            </li>
            <li>
              Stores information relevant to the creation and organization of
              data.
            </li>
          </ul>

          <br />

          <h4>5.9.3 Instructors</h4>
          <figure>
            <img
              src="assets/all_workspaces_instructor_view.png"
              class="case-study-image"
              alt="A screenshot of the instructor's dashboard in Armada."
            />
          </figure>

          <p>
            Within Armada, instructors are provided with several tools to
            create, organize, and manage their students' accounts and
            workspaces. Instructors can create individual accounts for students,
            group students into cohorts, and use those cohorts to enroll
            students into individual classes. Once a class has been populated,
            the instructor can generate individualized developer environments
            (i.e., workspaces) for every student. Each workspace is
            automatically associated with a given student and accessible through
            each student's student portal or through the instructor's "preview"
            button.
          </p>

          <br />

          <p>
            In addition, if an administrator needs to ensure that a student has
            the most up-to-date docker image for a given workspace, all they
            need to do is start and stop the service. ECS is automatically
            configured to retrieve the latest image when a container is created.
          </p>

          <br />

          <h4>5.9.4 Students</h4>
          <figure>
            <img
              src="assets/all_workspaces_student_view.png"
              class="case-study-image"
              alt="A screenshot of the student's dashboard in Armada."
            />
          </figure>

          <p>
            Armada provides a platform for students to access their workspaces.
            If a student's workspace is in an inactive state or has not yet
            entered a "running" state, the student can resume their workspace
            without instructor intervention. Most importantly, the student can
            connect to each of their workspaces and access all of their files.
          </p>

          <br />

          <h4>5.9.5 A Step Above</h4>

          <p>
            By utilizing the SDK and offering a user interface, we gained
            programmatic access to each of our provisioned resources and created
            a layer of abstraction on top of AWS that makes it easy for both
            instructors and students to manage and access workspaces. For our
            application to work, however, we need the ability to establish and
            retain relationships between the individual pieces of our data,
            allowing for organization and clarity.
          </p>

          <br />

          <h4>5.9.6 Establishing Relationships</h4>
          <figure>
            <img
              src="assets/database_erd.png"
              class="case-study-image"
              alt="An entity relationship diagram representing the relationships in Armada's database."
            />
          </figure>

          <p>
            Before we could begin serving Armada to instructors or workspaces to
            students, we needed a database within our architecture that would
            help us manage the relationships between workspaces, students,
            courses, and cohorts (the term we use for students grouped together
            by an instructor).
          </p>

          <br />

          <h5>To Host or Not to Host</h5>
          <figure>
            <img
              src="assets/self_hosted_database.png"
              class="case-study-image"
              alt="An architecture diagram demonstrating the Armada App interacting with a PostgreSQL instance."
            />
          </figure>

          <p>
            We initially considered implementing an instance of PostgreSQL,
            either on the server that would act as the host for Armada's backend
            or on a separate server intended solely to act as the host for the
            database. We quickly dismissed the former solution as we felt that
            it would be too fragile. Having decided that the database should be
            implemented on its own server, we then began to consider the
            possibility of using Amazon's managed solution, the Relational
            Database Service (RDS).
          </p>

          <br />

          <p>
            In some respects, provisioning a single EC2 instance to run
            PostgreSQL would have greatly simplified Armada's configuration. Had
            Armada been configured in this manner, it would have been trivial
            for the backend application to connect to the database and begin
            making queries. The only component that would need to be created
            would be a security group that allowed the backend application to
            communicate with the database host.
          </p>

          <br />

          <p>
            However, there were significant tradeoffs inherent in this approach.
            If this approach were selected, Armada would have been solely
            responsible for managing the database. Additionally, EC2 instances
            have ephemeral storage, and therefore, Armada would need to
            implement a mechanism for regularly backing up the database as well
            as methods to handle scenarios where the database crashed.
          </p>

          <br />

          <h5>Relational Database Service (RDS)</h5>
          <figure>
            <img
              src="assets/rds_architecture.png"
              class="case-study-image"
              alt="An architecture diagram illustrating RDS operating across availability zones."
            />
          </figure>

          <p>
            We decided that the cost of using RDS was low enough to justify
            using a managed service, as it traded ease of setup for a more
            resilient system in production. Our data would be automatically
            backed up and, in the event of a crash, RDS would automatically
            provision a replacement for our app.
          </p>

          <br />

          <p>
            Configuring the RDS instance to be accessible to the EC2 host for
            the backend app only required us to use a naming convention for
            those two resources in the CDK that automatically associated the
            database with the backend app's server. At this point we had a
            free-standing database that could manage all of the data relevant to
            the relationships among our users and their resources.
          </p>

          <br />

          <h5>The Admin Node</h5>
          <figure>
            <img
              src="assets/admin_node_rds.png"
              class="case-study-image"
              alt="An architecture diagram showing the RDS instance being configured by the Admin Node."
            />
          </figure>

          <p>
            The final piece of the puzzle required us to be able to initialize
            the database schema. We accomplished this by adding an IAM role to
            the EC2 instance that would allow the host to retrieve data vital to
            establishing a connection to the database via the AWS CLI. We then
            wrote startup scripts to run as soon as the hosts for the backend
            app and database are provisioned, and after the backend app's host
            is able to connect to the database we use the PostgreSQL client to
            initialize our schema. At this point, Armada was ready to handle all
            requests from instructors and students.
          </p>

          <br />

          <h5>Mischief Managed</h5>
          <figure>
            <img
              src="assets/architecture_rds_added.png"
              class="case-study-image"
              alt="An architecture diagram of Armada's current architecture with RDS added."
            />
          </figure>

          <p>
            With the database in place and the admin node able to connect and
            make requests to that database, we had a way to efficiently manage
            relationships between all of the entities required to serve
            students' workspaces and allow instructors to manage students,
            workspaces, and cohorts. What the database did not explicitly give
            us the ability to do was differentiate between types of users on
            login, i.e. whether or not a given user should have administrative
            privileges.
          </p>

          <br />

          <h3>5.10 Locking It Down</h3>

          <p>
            In order to offer differentiated access to our application we opted
            to create an authentication layer, which allowed us to direct users
            to the correct user interface on the app based on their role.
          </p>

          <br />

          <p>
            Authentication is notoriously a difficult area to develop due to the
            many issues around securely storing user credentials, warding off
            various types of attack by malicious actors, session management, and
            email and password retrieval. AWS has a managed solution for
            authentication with its Cognito service.
          </p>

          <br />

          <h4>5.10.1 In Cognito</h4>
          <figure>
            <img
              src="assets/cognito.png"
              class="case-study-image"
              alt="An architecture diagram with an instance of Cognito attached to the Armada App."
            />
          </figure>

          <p>
            Cognito is a tool to connect applications to AWS and provides
            authentication, authorization, and user management through user and
            identity pools. We were able to use the CDK to provision a user pool
            and an admin user whenever the Armada infrastructure is first
            deployed. Then, when an instructor adds students through the Armada
            interface, this adds a user to the Cognito user pool along with
            their credentials, adds the student to the RDS database, and sends
            an email to that student with a temporary password. The student is
            then able to log in to see their designated workspaces. Although
            authentication was a small part of our application, it was critical
            to integrating some of the isolated pieces of the Armada
            application.
          </p>

          <br />

          <h2 class="h2">6. Our Goals Achieved</h2>
          <figure>
            <img
              src="assets/final_architecture.png"
              class="case-study-image"
              alt="Armada's final architecture."
            />
          </figure>

          <p>
            With authentication and the database in place, we had a way to
            associate users of all types with the resources that they might want
            to access in Armada. This associated data meant that we could use
            all of the other components of Armada to serve students their
            specific workspaces in the browser and allow them to keep track of
            their work without having to perform any configuration or
            installations on their own machines. Instructors can also create
            custom development environments to deploy to an arbitrary number of
            students without needing to directly interact with AWS.
            Additionally, Armada's optimizations ensure the lowest cost for
            instructors, maximizing efficiency while preserving usability.
          </p>
          <br />

          <h2 class="h2">7. Future work</h2>
          <p>
            In the future, we would like Armada to have extended features that
            allow instructors to specify custom development environments for
            their courses using their own Docker images. This would allow for
            the ultimate flexibility in creating workspaces that are catered to
            an exact course or situation. Other avenues for improvement include:
          </p>
          <ul>
            <li>
              Creating a one-click deployment for AWS via CloudFormation to make
              generating the infrastructure easier.
            </li>
            <li>
              Creating a one-click deployment for AWS via CloudFormation to make
              generating the infrastructure easier.
            </li>
            <li>
              Integrating with GitHub repositories to allow the data from the
              repository to be automatically inserted into the generated
              workspaces.
            </li>
            <li>
              Integrating existing solutions either via VS Code Live Share or
              paid extensions that allow users to work collaboratively within a
              single environment.
            </li>
            <li>
              Implementing cost-saving measures such as spinning down ECS
              Services when the containers are not in use.
            </li>
          </ul>

          <br />
          <!-- Section 8 -->
          <h2>8. Team</h2>
          <br />
          <br />
          <div class="section team-section">
            <div class="container">
              <div
                data-duration-in="300"
                data-duration-out="100"
                class="tabs w-tabs"
              >
                <div
                  data-w-id="8ce4324a-ed8e-4436-9964-0cfbaf67c64a"
                  style="
                    transform: translate3d(0px, 55px, 0px) scale3d(1, 1, 1)
                      rotateX(0deg) rotateY(0deg) rotateZ(0deg) skew(0deg, 0deg);
                    transform-style: preserve-3d;
                    opacity: 0;
                  "
                  class="tabs-content w-tab-content"
                >
                  <div>
                    <div class="team-grid">
                      <div class="team-member-wrap">
                        <img
                          src="assets/images/team/Natalie.png"
                          loading="lazy"
                          alt="A picture of Natalie Martos"
                        />
                        <div class="team-member-info">
                          <div class="team-member-name">Natalie Martos</div>
                          <div class="team-member-location">
                            Philadelphia, PA
                          </div>
                        </div>
                        <ul class="team-member-icons">
                          <li>
                            <a
                              href="mailto:natalie.martos@gmail.com"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fas fa-envelope"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a href="https://natalie-ann.dev/" target="_blank">
                              <span class="team-member-icon">
                                <i class="fas fa-globe"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a
                              href="https://www.linkedin.com/in/natalie-martos/"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fab fa-linkedin"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a
                              href="https://github.com/Natalie-Ann"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fab fa-github"></i>
                              </span>
                            </a>
                          </li>
                        </ul>
                      </div>
                      <div class="team-member-wrap">
                        <img
                          src="assets/images/team/Sergio.png"
                          loading="lazy"
                          alt="A picture of Sergio Pichardo."
                        />
                        <div class="team-member-info">
                          <div class="team-member-name">Sergio Pichardo</div>
                          <div class="team-member-location">Starkville, MS</div>
                        </div>
                        <ul class="team-member-icons">
                          <li>
                            <!-- TODO: Add Sergio's email -->
                            <a
                              href="mailto:placeholder@gmail.com"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fas fa-envelope"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a
                              href="https://sergiojpichardo.com/"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fas fa-globe"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a
                              href="https://www.linkedin.com/in/sergiopichardo/"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fab fa-linkedin"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a
                              href="https://github.com/sergiopichardo"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fab fa-github"></i>
                              </span>
                            </a>
                          </li>
                        </ul>
                      </div>
                      <div class="team-member-wrap">
                        <img
                          src="assets/images/team/Joey.png"
                          loading="lazy"
                          alt="A picture of Joey Guillaume"
                        />
                        <div class="team-member-info">
                          <div class="team-member-name">Joey Guillaume</div>
                          <div class="team-member-location">Cleveland, OH</div>
                        </div>
                        <ul class="team-member-icons">
                          <li>
                            <a
                              href="mailto:josephdguillaume@gmail.com"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fas fa-envelope"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a href="https://jguillau.me/" target="_blank">
                              <span class="team-member-icon">
                                <i class="fas fa-globe"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a
                              href="https://www.linkedin.com/in/jdguillaume/"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fab fa-linkedin"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a
                              href="https://github.com/JDGuillaume"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fab fa-github"></i>
                              </span>
                            </a>
                          </li>
                        </ul>
                      </div>
                      <div class="team-member-wrap">
                        <img
                          src="assets/images/team/Del.jpg"
                          loading="lazy"
                          alt="A picture of Dean Elizardo."
                        />
                        <div class="team-member-info">
                          <div class="team-member-name">Dean Elizardo</div>
                          <div class="team-member-location">
                            Dallas-Fort Worth, TX
                          </div>
                        </div>
                        <ul class="team-member-icons">
                          <li>
                            <a
                              href="mailto:d.elizardo85@gmail.com"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fas fa-envelope"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a href="https://delizardo.com/" target="_blank">
                              <span class="team-member-icon">
                                <i class="fas fa-globe"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a
                              href="https://www.linkedin.com/in/dean-elizardo-85429a165/"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fab fa-linkedin"></i>
                              </span>
                            </a>
                          </li>
                          <li>
                            <a
                              href="https://github.com/Del-on-git"
                              target="_blank"
                            >
                              <span class="team-member-icon">
                                <i class="fab fa-github"></i>
                              </span>
                            </a>
                          </li>
                        </ul>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </article>
    </div>
    <script
      src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=5f71dd169010d641cf65485c"
      type="text/javascript"
      integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
      crossorigin="anonymous"
    ></script>
    <script
      src="https://assets.website-files.com/5f71dd169010d641cf65485c/js/webflow.6af2032ff.js"
      type="text/javascript"
    ></script>
    <script>
      /*!
       * toc - jQuery Table of Contents Plugin
       * v0.3.2
       * http://projects.jga.me/toc/
       * copyright Greg Allen 2014
       * MIT License
       */
      !(function (a) {
        (a.fn.smoothScroller = function (b) {
          b = a.extend({}, a.fn.smoothScroller.defaults, b);
          var c = a(this);
          return (
            a(b.scrollEl).animate(
              {
                scrollTop:
                  c.offset().top - a(b.scrollEl).offset().top - b.offset,
              },
              b.speed,
              b.ease,
              function () {
                var a = c.attr('id');
                a.length &&
                  (history.pushState
                    ? history.pushState(null, null, '#' + a)
                    : (document.location.hash = a)),
                  c.trigger('smoothScrollerComplete');
              }
            ),
            this
          );
        }),
          (a.fn.smoothScroller.defaults = {
            speed: 400,
            ease: 'swing',
            scrollEl: 'body,html',
            offset: 0,
          }),
          a('body').on('click', '[data-smoothscroller]', function (b) {
            b.preventDefault();
            var c = a(this).attr('href');
            0 === c.indexOf('#') && a(c).smoothScroller();
          });
      })(jQuery),
        (function (a) {
          var b = {};
          (a.fn.toc = function (b) {
            var c,
              d = this,
              e = a.extend({}, jQuery.fn.toc.defaults, b),
              f = a(e.container),
              g = a(e.selectors, f),
              h = [],
              i = e.activeClass,
              j = function (b, c) {
                if (
                  e.smoothScrolling &&
                  'function' == typeof e.smoothScrolling
                ) {
                  b.preventDefault();
                  var f = a(b.target).attr('href');
                  e.smoothScrolling(f, e, c);
                }
                a('li', d).removeClass(i), a(b.target).parent().addClass(i);
              },
              k = function () {
                c && clearTimeout(c),
                  (c = setTimeout(function () {
                    for (
                      var b,
                        c = a(window).scrollTop(),
                        f = Number.MAX_VALUE,
                        g = 0,
                        j = 0,
                        k = h.length;
                      k > j;
                      j++
                    ) {
                      var l = Math.abs(h[j] - c);
                      f > l && ((g = j), (f = l));
                    }
                    a('li', d).removeClass(i),
                      (b = a('li:eq(' + g + ')', d).addClass(i)),
                      e.onHighlight(b);
                  }, 50));
              };
            return (
              e.highlightOnScroll && (a(window).bind('scroll', k), k()),
              this.each(function () {
                var b = a(this),
                  c = a(e.listType);
                g.each(function (d, f) {
                  var g = a(f);
                  h.push(g.offset().top - e.highlightOffset);
                  var i = e.anchorName(d, f, e.prefix);
                  if (f.id !== i) {
                    a('<span/>').attr('id', i).insertBefore(g);
                  }
                  var l = a('<a/>')
                      .text(e.headerText(d, f, g))
                      .attr('href', '#' + i)
                      .bind('click', function (c) {
                        a(window).unbind('scroll', k),
                          j(c, function () {
                            a(window).bind('scroll', k);
                          }),
                          b.trigger('selected', a(this).attr('href'));
                      }),
                    m = a('<li/>')
                      .addClass(e.itemClass(d, f, g, e.prefix))
                      .append(l);
                  c.append(m);
                }),
                  b.html(c);
              })
            );
          }),
            (jQuery.fn.toc.defaults = {
              container: 'body',
              listType: '<ul/>',
              selectors: 'h1,h2,h3',
              smoothScrolling: function (b, c, d) {
                a(b)
                  .smoothScroller({ offset: c.scrollToOffset })
                  .on('smoothScrollerComplete', function () {
                    d();
                  });
              },
              scrollToOffset: 0,
              prefix: 'toc',
              activeClass: 'toc-active',
              onHighlight: function () {},
              highlightOnScroll: !0,
              highlightOffset: 100,
              anchorName: function (c, d, e) {
                if (d.id.length) return d.id;
                var f = a(d)
                  .text()
                  .replace(/[^a-z0-9]/gi, ' ')
                  .replace(/\s+/g, '-')
                  .toLowerCase();
                if (b[f]) {
                  for (var g = 2; b[f + g]; ) g++;
                  f = f + '-' + g;
                }
                return (b[f] = !0), e + '-' + f;
              },
              headerText: function (a, b, c) {
                return c.text();
              },
              itemClass: function (a, b, c, d) {
                return d + '-' + c[0].tagName.toLowerCase();
              },
            });
        })(jQuery);
    </script>
    <script>
      /* initialize */
      $('.toc').toc({
        selectors: 'h2', //elements to use as headings
        container: 'article', //element to find all selectors in
        smoothScrolling: true, //enable or disable smooth scrolling on click
        prefix: 'toc', //prefix for anchor tags and class names
        highlightOnScroll: true, //add class to heading that is currently in focus
        highlightOffset: 100, //offset to trigger the next headline
      });
    </script>
  </body>
</html>
